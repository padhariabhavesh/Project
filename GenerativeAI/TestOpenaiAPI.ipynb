{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is OpenAI API?\n",
    "\n",
    "The OpenAI API refers to the application programming interface provided by OpenAI, a leading artificial intelligence research lab. The OpenAI API allows developers to access and integrate OpenAI's powerful language models into their own applications, products, or services.\n",
    "\n",
    "One notable model offered through the OpenAI API is GPT (Generative Pre-trained Transformer). GPT models are designed for natural language processing tasks, such as text generation, completion, translation, summarization, and more. The API provides a way for developers to interact with these models and leverage their capabilities without having to train the models from scratch.\n",
    "\n",
    "Keep in mind that the specifics of the OpenAI API, including its features and offerings, may have evolved since my last update in January 2022. Therefore, it's a good idea to check the official OpenAI website or other reliable sources for the most up-to-date information on the OpenAI API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate OPEN API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Myapi = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = Myapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Models = openai.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
       " Model(id='curie-search-query', created=1651172509, object='model', owned_by='openai-dev'),\n",
       " Model(id='babbage-search-query', created=1651172509, object='model', owned_by='openai-dev'),\n",
       " Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
       " Model(id='babbage-search-document', created=1651172510, object='model', owned_by='openai-dev'),\n",
       " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
       " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
       " Model(id='davinci-search-query', created=1651172505, object='model', owned_by='openai-dev'),\n",
       " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
       " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
       " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
       " Model(id='ada-search-document', created=1651172507, object='model', owned_by='openai-dev'),\n",
       " Model(id='ada-code-search-code', created=1651172505, object='model', owned_by='openai-dev'),\n",
       " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
       " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
       " Model(id='davinci-search-document', created=1651172509, object='model', owned_by='openai-dev'),\n",
       " Model(id='curie-search-document', created=1651172508, object='model', owned_by='openai-dev'),\n",
       " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
       " Model(id='ada-search-query', created=1651172505, object='model', owned_by='openai-dev'),\n",
       " Model(id='ada-code-search-text', created=1651172510, object='model', owned_by='openai-dev'),\n",
       " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
       " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
       " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(All_Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Created</th>\n",
       "      <th>Object</th>\n",
       "      <th>Owned_By</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(id, gpt-3.5-turbo-0613)</td>\n",
       "      <td>(created, 1686587434)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(id, curie-search-query)</td>\n",
       "      <td>(created, 1651172509)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-dev)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(id, babbage-search-query)</td>\n",
       "      <td>(created, 1651172509)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-dev)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(id, dall-e-3)</td>\n",
       "      <td>(created, 1698785189)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(id, babbage-search-document)</td>\n",
       "      <td>(created, 1651172510)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-dev)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(id, dall-e-2)</td>\n",
       "      <td>(created, 1698798177)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(id, gpt-3.5-turbo-0301)</td>\n",
       "      <td>(created, 1677649963)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k-0613)</td>\n",
       "      <td>(created, 1685474247)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(id, text-embedding-ada-002)</td>\n",
       "      <td>(created, 1671217299)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(id, davinci-search-query)</td>\n",
       "      <td>(created, 1651172505)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-dev)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(id, tts-1-hd-1106)</td>\n",
       "      <td>(created, 1699053533)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct)</td>\n",
       "      <td>(created, 1692901427)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k)</td>\n",
       "      <td>(created, 1683758102)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(id, whisper-1)</td>\n",
       "      <td>(created, 1677532384)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(id, tts-1-hd)</td>\n",
       "      <td>(created, 1699046015)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(id, ada-search-document)</td>\n",
       "      <td>(created, 1651172507)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-dev)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(id, ada-code-search-code)</td>\n",
       "      <td>(created, 1651172505)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-dev)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(id, davinci-002)</td>\n",
       "      <td>(created, 1692634301)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct-0914)</td>\n",
       "      <td>(created, 1694122472)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(id, babbage-002)</td>\n",
       "      <td>(created, 1692634615)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(id, davinci-search-document)</td>\n",
       "      <td>(created, 1651172509)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-dev)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(id, curie-search-document)</td>\n",
       "      <td>(created, 1651172508)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-dev)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(id, gpt-3.5-turbo)</td>\n",
       "      <td>(created, 1677610602)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(id, ada-search-query)</td>\n",
       "      <td>(created, 1651172505)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-dev)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(id, ada-code-search-text)</td>\n",
       "      <td>(created, 1651172510)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-dev)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(id, gpt-3.5-turbo-1106)</td>\n",
       "      <td>(created, 1698959748)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(id, tts-1-1106)</td>\n",
       "      <td>(created, 1699053241)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(id, tts-1)</td>\n",
       "      <td>(created, 1681940951)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ID                Created           Object  \\\n",
       "0            (id, gpt-3.5-turbo-0613)  (created, 1686587434)  (object, model)   \n",
       "1            (id, curie-search-query)  (created, 1651172509)  (object, model)   \n",
       "2          (id, babbage-search-query)  (created, 1651172509)  (object, model)   \n",
       "3                      (id, dall-e-3)  (created, 1698785189)  (object, model)   \n",
       "4       (id, babbage-search-document)  (created, 1651172510)  (object, model)   \n",
       "5                      (id, dall-e-2)  (created, 1698798177)  (object, model)   \n",
       "6            (id, gpt-3.5-turbo-0301)  (created, 1677649963)  (object, model)   \n",
       "7        (id, gpt-3.5-turbo-16k-0613)  (created, 1685474247)  (object, model)   \n",
       "8        (id, text-embedding-ada-002)  (created, 1671217299)  (object, model)   \n",
       "9          (id, davinci-search-query)  (created, 1651172505)  (object, model)   \n",
       "10                (id, tts-1-hd-1106)  (created, 1699053533)  (object, model)   \n",
       "11       (id, gpt-3.5-turbo-instruct)  (created, 1692901427)  (object, model)   \n",
       "12            (id, gpt-3.5-turbo-16k)  (created, 1683758102)  (object, model)   \n",
       "13                    (id, whisper-1)  (created, 1677532384)  (object, model)   \n",
       "14                     (id, tts-1-hd)  (created, 1699046015)  (object, model)   \n",
       "15          (id, ada-search-document)  (created, 1651172507)  (object, model)   \n",
       "16         (id, ada-code-search-code)  (created, 1651172505)  (object, model)   \n",
       "17                  (id, davinci-002)  (created, 1692634301)  (object, model)   \n",
       "18  (id, gpt-3.5-turbo-instruct-0914)  (created, 1694122472)  (object, model)   \n",
       "19                  (id, babbage-002)  (created, 1692634615)  (object, model)   \n",
       "20      (id, davinci-search-document)  (created, 1651172509)  (object, model)   \n",
       "21        (id, curie-search-document)  (created, 1651172508)  (object, model)   \n",
       "22                (id, gpt-3.5-turbo)  (created, 1677610602)  (object, model)   \n",
       "23             (id, ada-search-query)  (created, 1651172505)  (object, model)   \n",
       "24         (id, ada-code-search-text)  (created, 1651172510)  (object, model)   \n",
       "25           (id, gpt-3.5-turbo-1106)  (created, 1698959748)  (object, model)   \n",
       "26                   (id, tts-1-1106)  (created, 1699053241)  (object, model)   \n",
       "27                        (id, tts-1)  (created, 1681940951)  (object, model)   \n",
       "\n",
       "                       Owned_By  \n",
       "0            (owned_by, openai)  \n",
       "1        (owned_by, openai-dev)  \n",
       "2        (owned_by, openai-dev)  \n",
       "3            (owned_by, system)  \n",
       "4        (owned_by, openai-dev)  \n",
       "5            (owned_by, system)  \n",
       "6            (owned_by, openai)  \n",
       "7            (owned_by, openai)  \n",
       "8   (owned_by, openai-internal)  \n",
       "9        (owned_by, openai-dev)  \n",
       "10           (owned_by, system)  \n",
       "11           (owned_by, system)  \n",
       "12  (owned_by, openai-internal)  \n",
       "13  (owned_by, openai-internal)  \n",
       "14           (owned_by, system)  \n",
       "15       (owned_by, openai-dev)  \n",
       "16       (owned_by, openai-dev)  \n",
       "17           (owned_by, system)  \n",
       "18           (owned_by, system)  \n",
       "19           (owned_by, system)  \n",
       "20       (owned_by, openai-dev)  \n",
       "21       (owned_by, openai-dev)  \n",
       "22           (owned_by, openai)  \n",
       "23       (owned_by, openai-dev)  \n",
       "24       (owned_by, openai-dev)  \n",
       "25           (owned_by, system)  \n",
       "26           (owned_by, system)  \n",
       "27  (owned_by, openai-internal)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(All_Models), columns = [\"ID\",\"Created\", \"Object\",\"Owned_By\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code of OpenAI Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"How I can Make Money?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is where you make a request to the OpenAI API for generating a chat completion. Let's break down the parameters:\n",
    "\n",
    "    model=\"gpt-3.5-turbo\": Specifies the language model to be used, in this case, GPT-3.5-turbo.\n",
    "\n",
    "    messages: A list of message objects representing the conversation. In this example, there is only one message from the user: \"How I can Make Money?\".\n",
    "\n",
    "    temperature=1: A parameter controlling the randomness of the model's output. Higher values like 1 make the output more random, while lower values like 0.2 make it more focused and deterministic.\n",
    "\n",
    "    max_tokens=256: Specifies the maximum number of tokens (words or characters) in the generated response.\n",
    "\n",
    "    top_p=1: Top-p (nucleus) sampling probability. Setting it to 1 means the model considers the entire probability distribution for sampling.\n",
    "\n",
    "    frequency_penalty=0: Controls the penalty for using frequent tokens. A higher value will make the model more creative, while a lower value will make it more conservative.\n",
    "\n",
    "    presence_penalty=0: Controls the penalty for using new tokens. Similar to frequency_penalty, but for unseen tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain for Generative AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Calling : Learn how to connect Large Language Models to external tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example invoking multiple function calls in one response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response\n",
    "print(run_conversation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(openai_api_key=Myapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero short prompting\n",
    "prompt = \"Can you tell me total number of country in Aisa?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
